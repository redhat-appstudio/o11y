evaluation_interval: 1m

rule_files:
  - prometheus.performance_alerts.yaml

tests:
  # Etcd Alerts
  - interval: 1m
    input_series:
      # Average Fsync latency higher than 40ms, so it will be alerted.
      - series: 'etcd_disk_wal_fsync_duration_seconds_bucket{le="0.05", pod="etcd-pod-1", source_cluster="cluster01"}'
        values: '0+0.01x15'

      - series: 'etcd_disk_wal_fsync_duration_seconds_bucket{le="+Inf", pod="etcd-pod-1", source_cluster="cluster01"}'
        values: '0+0.1x15'

    alert_rule_test:
      - eval_time: 15m
        alertname: EtcdFsyncLatency
        exp_alerts:
          - exp_labels:
              severity: warning
              pod: etcd-pod-1
              source_cluster: cluster01
            exp_annotations:
              summary: "ETCD slow file system synchronization."
              description: "10 minutes avg. 99th etcd fsync latency on etcd-pod-1 higher than 40ms in cluster cluster01."
              alert_routing_key: perfandscale

  - interval: 1m
    input_series:
      # Average Fsync latency is below alert threshold, so it will not be alerted.
      - series: 'etcd_disk_wal_fsync_duration_seconds_bucket{le="0.01", pod="etcd-pod-2", source_cluster="cluster01"}'
        values: '2+0.01x15'

    alert_rule_test:
      - eval_time: 15m
        alertname: EtcdFsyncLatency


  - interval: 1m
    input_series:
      # Average commit latency higher than 40ms, so it will be alerted.
      - series: 'etcd_disk_backend_commit_duration_seconds_bucket{le="0.05", pod="etcd-pod-1", source_cluster="cluster01"}'
        values: '0+0.01x15'

      - series: 'etcd_disk_backend_commit_duration_seconds_bucket{le="+Inf", pod="etcd-pod-1", source_cluster="cluster01"}'
        values: '0+0.5x15'

    alert_rule_test:
      - eval_time: 15m
        alertname: EtcdCommitLatency
        exp_alerts:
          - exp_labels:
              severity: warning
              pod: etcd-pod-1
              source_cluster: cluster01
            exp_annotations:
              summary: "ETCD slow writes observed."
              description: "10 minutes avg. 99th etcd commit latency on etcd-pod-1 higher than 40ms in cluster cluster01."
              alert_routing_key: perfandscale

  - interval: 1m
    input_series:
      # Average commit latency higher than 40ms on a cluster we do not care about, so it will not be alerted.
      - series: 'etcd_disk_backend_commit_duration_seconds_bucket{le="0.05", pod="etcd-pod-1", source_cluster="cluster01"}'
        values: '2+0x15'

      - series: 'etcd_disk_backend_commit_duration_seconds_bucket{le="+Inf", pod="etcd-pod-1", source_cluster="cluster01"}'
        values: '2+0x15'

      - series: 'etcd_disk_backend_commit_duration_seconds_bucket{le="0.05", pod="etcd-pod-1"}'
        values: '0+0.01x15'

      - series: 'etcd_disk_backend_commit_duration_seconds_bucket{le="+Inf", pod="etcd-pod-1"}'
        values: '0+0.5x15'

    alert_rule_test:
      - eval_time: 15m
        alertname: EtcdCommitLatency

  - interval: 1m
    input_series:
      # Average commit latency is below alert threshold count, so it will not be alerted.
      - series: 'etcd_disk_backend_commit_duration_seconds_bucket{le="0.03", pod="etcd-pod-2", source_cluster="cluster01"}'
        values: '2+0.01x15'

    alert_rule_test:
      - eval_time: 15m
        alertname: EtcdCommitLatency

  - interval: 1m
    input_series:
      # Etcd cluster member RTT delay is over 0.1, so it will be alerted.
      - series: 'etcd_network_peer_round_trip_time_seconds_bucket{le="0.01", pod="etcd-pod-1", source_cluster="cluster01"}'
        values: '0.1+0.3x16'

      - series: 'etcd_network_peer_round_trip_time_seconds_bucket{le="0.2", pod="etcd-pod-1", source_cluster="cluster01"}'
        values: '0.1+0.5x16'

      - series: 'etcd_network_peer_round_trip_time_seconds_bucket{le="+Inf", pod="etcd-pod-1", source_cluster="cluster01"}'
        values: '0.1+0.2x16'

    alert_rule_test:
      - eval_time: 16m
        alertname: EtcdSlowNetworkRTT
        exp_alerts:
          - exp_labels:
              severity: warning
              pod: etcd-pod-1
              source_cluster: cluster01
            exp_annotations:
              summary: "High RTT latency on ETCD cluster member requests."
              description: "99th etcd RTT latency rate on etcd-pod-1 higher than 0.1 in cluster cluster01."
              alert_routing_key: perfandscale

  - interval: 1m
    input_series:
      # Etcd cluster member RTT delay is over 0.1 on second pod, so it will be alerted.
      - series: 'etcd_network_peer_round_trip_time_seconds_bucket{le="0.01", pod="etcd-pod-1", source_cluster="cluster01"}'
        values: '0.01+0x15'

      - series: 'etcd_network_peer_round_trip_time_seconds_bucket{le="0.2", pod="etcd-pod-1", source_cluster="cluster01"}'
        values: '0.01+0x15'

      - series: 'etcd_network_peer_round_trip_time_seconds_bucket{le="+Inf", pod="etcd-pod-1", source_cluster="cluster01"}'
        values: '0.01+0x15'

      - series: 'etcd_network_peer_round_trip_time_seconds_bucket{le="0.01", pod="etcd-pod-2", source_cluster="cluster01"}'
        values: '0.1+0.3x15'

      - series: 'etcd_network_peer_round_trip_time_seconds_bucket{le="0.2", pod="etcd-pod-2", source_cluster="cluster01"}'
        values: '0.1+0.5x15'

      - series: 'etcd_network_peer_round_trip_time_seconds_bucket{le="+Inf", pod="etcd-pod-2", source_cluster="cluster01"}'
        values: '0.1+0.2x15'

    alert_rule_test:
      - eval_time: 16m
        alertname: EtcdSlowNetworkRTT
        exp_alerts:
          - exp_labels:
              severity: warning
              pod: etcd-pod-2
              source_cluster: cluster01
            exp_annotations:
              summary: "High RTT latency on ETCD cluster member requests."
              description: "99th etcd RTT latency rate on etcd-pod-2 higher than 0.1 in cluster cluster01."
              alert_routing_key: perfandscale

  - interval: 1m
    input_series:
      # Etcd cluster member RTT delay is below alert threshold rate, so it will not be alerted.
      - series: 'etcd_network_peer_round_trip_time_seconds_bucket{le="0.1", pod="etcd-pod-2", source_cluster="cluster01"}'
        values: '0.1+0.01x16'

    alert_rule_test:
      - eval_time: 16m
        alertname: EtcdSlowNetworkRTT


  - interval: 1m
    input_series:
      # Increase in Etcd raft proposal failures over time, so it will be alerted.
      - series: 'etcd_server_proposals_failed_total{pod="etcd-pod-1", source_cluster="cluster01"}'
        values: '0+5x60'

      - series: 'etcd_server_proposals_failed_total{pod="etcd-pod-2", source_cluster="cluster01"}'
        values: '0+0x60'

      - series: 'etcd_server_proposals_failed_total{pod="etcd-pod-3", source_cluster="cluster01"}'
        values: '0+0x60'

    alert_rule_test:
      - eval_time: 1h
        alertname: EtcdProposalFailures
        exp_alerts:
          - exp_labels:
              severity: warning
              source_cluster: cluster01
            exp_annotations:
              summary: "ETCD raft proposal failures."
              description: "Etcd high number of failed proposals on some etcd pod in cluster cluster01."
              alert_routing_key: perfandscale

  - interval: 1m
    input_series:
      # Etcd raft proposals failures within threshold limit, so it will not be alerted.
      - series: 'etcd_server_proposals_failed_total{pod="etcd-pod-1", source_cluster="cluster01"}'
        values: '0+5x30 1+0x30'

      - series: 'etcd_server_proposals_failed_total{pod="etcd-pod-2", source_cluster="cluster01"}'
        values: '0+5x30 1+0x30'

      - series: 'etcd_server_proposals_failed_total{pod="etcd-pod-3", source_cluster="cluster01"}'
        values: '0+5x30 1+0x30'

    alert_rule_test:
      - eval_time: 1h
        alertname: EtcdProposalFailures

  # KubeAPI Alerts
  - interval: 1m
    input_series:
      # Run status of 2 jobs are not available, so it will be alerted.
      - series: 'kube_job_spec_completions{namespace="default", job_name="example-job", source_cluster="cluster01"}'
        values: '3+0x70'

      # Status: 0 job succeeded
      - series: 'kube_job_status_succeeded{namespace="default", job_name="example-job", source_cluster="cluster01"}'
        values: '0+0x70'

      # Status: 1 jobs failed
      - series: 'kube_job_status_failed{namespace="default", job_name="example-job", source_cluster="cluster01"}'
        values: '1+0x70'

    alert_rule_test:
      - eval_time: 70m
        alertname: KubernetesLongRunningJob
        exp_alerts:
          - exp_labels:
              severity: warning
              job_name: example-job
              namespace: default
              source_cluster: cluster01
            exp_annotations:
              summary: "Kubernetes Job slow completion."
              description: "Kubernetes Job default/example-job running for long duration in cluster cluster01."
              alert_routing_key: perfandscale

  - interval: 1m
    input_series:
      # Run status of 1 job is not available, so it will be alerted.
      - series: 'kube_job_spec_completions{namespace="default", job_name="example-job", source_cluster="cluster01"}'
        values: '3+0x70'

      # Status: 2 job succeeded
      - series: 'kube_job_status_succeeded{namespace="default", job_name="example-job", source_cluster="cluster01"}'
        values: '2+0x70'

      # Status: 0 jobs failed
      - series: 'kube_job_status_failed{namespace="default", job_name="example-job", source_cluster="cluster01"}'
        values: '0+0x70'

    alert_rule_test:
      - eval_time: 70m
        alertname: KubernetesLongRunningJob
        exp_alerts:
          - exp_labels:
              severity: warning
              job_name: example-job
              namespace: default
              source_cluster: cluster01
            exp_annotations:
              summary: "Kubernetes Job slow completion."
              description: "Kubernetes Job default/example-job running for long duration in cluster cluster01."
              alert_routing_key: perfandscale

  - interval: 1m
    input_series:
      # Run status of all jobs are available, so it will not be alerted.
      - series: 'kube_job_spec_completions{namespace="default", job_name="example-job", source_cluster="cluster01"}'
        values: '3+0x70'

      # Status: 3 job succeeded
      - series: 'kube_job_status_succeeded{namespace="default", job_name="example-job", source_cluster="cluster01"}'
        values: '3+0x70'

      # Status: 0 jobs failed
      - series: 'kube_job_status_failed{namespace="default", job_name="example-job", source_cluster="cluster01"}'
        values: '0+0x70'

    alert_rule_test:
      - eval_time: 70m
        alertname: KubernetesLongRunningJob

  - interval: 1m
    input_series:
      #  Run status of all jobs are available, so it will not be alerted.
      - series: 'kube_job_spec_completions{namespace="default", job_name="example-job", source_cluster="cluster01"}'
        values: '3+0x70'

      # Status: 2 job succeeded
      - series: 'kube_job_status_succeeded{namespace="default", job_name="example-job", source_cluster="cluster01"}'
        values: '2+0x70'

      # Status: 0 jobs failed
      - series: 'kube_job_status_failed{namespace="default", job_name="example-job", source_cluster="cluster01"}'
        values: '1+0x70'

    alert_rule_test:
      - eval_time: 70m
        alertname: KubernetesLongRunningJob

  # Node based Alerts
  - interval: 1m
    input_series:
      # Node is running with 100% CPU usage, so it will be alerted.
      - series: 'node_cpu_seconds_total{instance="instance1", mode="idle", source_cluster="cluster01"}'
        values: '0.01+0x15'
      - series: 'node_cpu_seconds_total{instance="instance2", mode="idle", source_cluster="cluster01"}'
        values: '0.01+0x15'
      - series: 'node_cpu_seconds_total{instance="instance3", mode="idle", source_cluster="cluster01"}'
        values: '0.01+0x15'

    alert_rule_test:
      - eval_time: 15m
        alertname: NodeHighCPU
        exp_alerts:
          - exp_labels:
              severity: high
              source_cluster: cluster01
            exp_annotations:
              summary: "Instances with high CPU in cluster01"
              description: "More than 2 instances in cluster cluster01 have had CPU usage above 95% for the last 5 minutes."
              alert_routing_key: perfandspreandinfra

  - interval: 1m
    input_series:
      # Node is running under 95% CPU usage, so it will not be alerted.
      - series: 'node_cpu_seconds_total{instance="instance1", mode="idle", source_cluster="cluster01"}'
        values: '0.75-0.1x10'
      - series: 'node_cpu_seconds_total{instance="instance2", mode="idle", source_cluster="cluster01"}'
        values: '0.85+0x10'

    alert_rule_test:
      - eval_time: 15m
        alertname: NodeHighCPU

  - interval: 1m
    input_series:
      # Node is running with 98% memory usage, so it will be alerted.
      - series: 'node_memory_MemTotal_bytes{instance="instance1", source_cluster="cluster01"}'
        values: '100+0x9'
      - series: 'node_memory_MemAvailable_bytes{instance="instance1", source_cluster="cluster01"}'
        values: '2+0x9'

    alert_rule_test:
      - eval_time: 10m
        alertname: NodeHighMemory
        exp_alerts:
          - exp_labels:
              severity: high
              instance: instance1
              source_cluster: cluster01
            exp_annotations:
              summary: "Node High Memory Usage."
              description: "Memory Usage is 98% on node instance1 in cluster cluster01."
              alert_routing_key: perfandspreandinfra

  - interval: 1m
    input_series:
      # Node is running under 90% memory usage, so it will not be alerted.
      - series: 'node_memory_MemTotal_bytes{instance="instance2", source_cluster="cluster01"}'
        values: '100x9'
      - series: 'node_memory_MemAvailable_bytes{instance="instance2", source_cluster="cluster01"}'
        values: '98x9'

    alert_rule_test:
      - eval_time: 10m
        alertname: NodeHighMemory
