evaluation_interval: 1m

rule_files:
  - prometheus.performance_alerts.yaml

tests:
  # Etcd Alerts
  - interval: 1m
    input_series:
      # Average Fsync latency higher than 10ms, so it will be alerted.
      - series: 'etcd_disk_wal_fsync_duration_seconds_bucket{le="0.02", pod="etcd-pod-1"}'
        values: '0+0.01x15'

      - series: 'etcd_disk_wal_fsync_duration_seconds_bucket{le="+Inf", pod="etcd-pod-1"}'
        values: '0+0.1x15'

    alert_rule_test:
      - eval_time: 15m
        alertname: EtcdFsyncLatency
        exp_alerts:
          - exp_labels:
              severity: warning
              pod: etcd-pod-1
            exp_annotations:
              summary: "ETCD slow file system synchronization."
              description: "10 minutes avg. 99th etcd fsync latency on etcd-pod-1 higher than 10ms."
              alert_routing_key: perfandscale

  - interval: 1m
    input_series:
      # Average Fsync latency is below alert threshold, so it will not be alerted.
      - series: 'etcd_disk_wal_fsync_duration_seconds_bucket{le="0.01", pod="etcd-pod-2"}'
        values: '2+0.01x15'

    alert_rule_test:
      - eval_time: 15m
        alertname: EtcdFsyncLatency


  - interval: 1m
    input_series:
      # Average commit latency higher than 30ms, so it will be alerted.
      - series: 'etcd_disk_backend_commit_duration_seconds_bucket{le="0.04", pod="etcd-pod-1"}'
        values: '0+0.01x15'

      - series: 'etcd_disk_backend_commit_duration_seconds_bucket{le="+Inf", pod="etcd-pod-1"}'
        values: '0+0.5x15'

    alert_rule_test:
      - eval_time: 15m
        alertname: EtcdCommitLatency
        exp_alerts:
          - exp_labels:
              severity: warning
              pod: etcd-pod-1
            exp_annotations:
              summary: "ETCD slow writes observed."
              description: "10 minutes avg. 99th etcd commit latency on etcd-pod-1 higher than 30ms."
              alert_routing_key: perfandscale

  - interval: 1m
    input_series:
      # Average commit latency is below alert threshold count, so it will not be alerted.
      - series: 'etcd_disk_backend_commit_duration_seconds_bucket{le="0.03", pod="etcd-pod-2"}'
        values: '2+0.01x15'

    alert_rule_test:
      - eval_time: 15m
        alertname: EtcdCommitLatency

  - interval: 1m
    input_series:
      # Etcd cluster member RTT delay is over 0.1, so it will be alerted.
      - series: 'etcd_network_peer_round_trip_time_seconds_bucket{le="0.01", pod="etcd-pod-1"}'
        values: '0.1+0.3x15'

      - series: 'etcd_network_peer_round_trip_time_seconds_bucket{le="0.2", pod="etcd-pod-1"}'
        values: '0.1+0.5x15'

      - series: 'etcd_network_peer_round_trip_time_seconds_bucket{le="+Inf", pod="etcd-pod-1"}'
        values: '0.1+0.2x15'

    alert_rule_test:
      - eval_time: 16m
        alertname: EtcdSlowNetworkRTT
        exp_alerts:
          - exp_labels:
              severity: warning
              pod: etcd-pod-1
            exp_annotations:
              summary: "High RTT latency on ETCD cluster member requests."
              description: "99th etcd RTT latency rate on etcd-pod-1 higher than 0.1"
              alert_routing_key: perfandscale

  - interval: 1m
    input_series:
      # Etcd cluster member RTT delay is below alert threshold rate, so it will not be alerted.
      - series: 'etcd_network_peer_round_trip_time_seconds_bucket{le="0.1", pod="etcd-pod-2"}'
        values: '0.1+0.01x15'

    alert_rule_test:
      - eval_time: 15m
        alertname: EtcdSlowNetworkRTT


  - interval: 1m
    input_series:
      # Increase in Etcd raft proposal failures over time, so it will be alerted.
      - series: 'etcd_server_proposals_failed_total{pod="etcd-pod-1"}'
        values: '0+5x59'

    alert_rule_test:
      - eval_time: 1h
        alertname: EtcdProposalFailures
        exp_alerts:
          - exp_labels:
              severity: warning
              pod: etcd-pod-1
            exp_annotations:
              summary: "ETCD raft proposal failures."
              description: "Etcd high number of failed proposals on pod etcd-pod-1"
              alert_routing_key: perfandscale

  - interval: 1m
    input_series:
      # Etcd raft proposals failures within threshold limit, so it will not be alerted.
      - series: 'etcd_server_proposals_failed_total{pod="etcd-pod-1"}'
        values: '0+5x30 1+0x29'

    alert_rule_test:
      - eval_time: 1h
        alertname: EtcdProposalFailures

  # KubeAPI Alerts
  - interval: 1m
    input_series:
      # Run status of 2 jobs are not available, so it will be alerted.
      - series: 'kube_job_spec_completions{namespace="default", job_name="example-job"}'
        values: '3+0x15'

      # Status: 0 job succeeded
      - series: 'kube_job_status_succeeded{namespace="default", job_name="example-job"}'
        values: '0+0x15'

      # Status: 1 jobs failed
      - series: 'kube_job_status_failed{namespace="default", job_name="example-job"}'
        values: '1+0x15'

    alert_rule_test:
      - eval_time: 20m
        alertname: KubernetesLongRunningJob
        exp_alerts:
          - exp_labels:
              severity: warning
              job_name: example-job
              namespace: default
            exp_annotations:
              summary: "Kubernetes Job slow completion."
              description: "Kubernetes Job default/example-job running for long duration."
              alert_routing_key: perfandscale

  - interval: 1m
    input_series:
      # Run status of 1 job is not available, so it will be alerted.
      - series: 'kube_job_spec_completions{namespace="default", job_name="example-job"}'
        values: '3+0x20'

      # Status: 2 job succeeded
      - series: 'kube_job_status_succeeded{namespace="default", job_name="example-job"}'
        values: '2+0x20'

      # Status: 0 jobs failed
      - series: 'kube_job_status_failed{namespace="default", job_name="example-job"}'
        values: '0+0x20'

    alert_rule_test:
      - eval_time: 20m
        alertname: KubernetesLongRunningJob
        exp_alerts:
          - exp_labels:
              severity: warning
              job_name: example-job
              namespace: default
            exp_annotations:
              summary: "Kubernetes Job slow completion."
              description: "Kubernetes Job default/example-job running for long duration."
              alert_routing_key: perfandscale

  - interval: 1m
    input_series:
      # Run status of all jobs are available, so it will not be alerted.
      - series: 'kube_job_spec_completions{namespace="default", job_name="example-job"}'
        values: '3+0x20'

      # Status: 3 job succeeded
      - series: 'kube_job_status_succeeded{namespace="default", job_name="example-job"}'
        values: '3+0x20'

      # Status: 0 jobs failed
      - series: 'kube_job_status_failed{namespace="default", job_name="example-job"}'
        values: '0+0x20'

    alert_rule_test:
      - eval_time: 20m
        alertname: KubernetesLongRunningJob

  - interval: 1m
    input_series:
      #  Run status of all jobs are available, so it will not be alerted.
      - series: 'kube_job_spec_completions{namespace="default", job_name="example-job"}'
        values: '3+0x20'

      # Status: 2 job succeeded
      - series: 'kube_job_status_succeeded{namespace="default", job_name="example-job"}'
        values: '2+0x20'

      # Status: 0 jobs failed
      - series: 'kube_job_status_failed{namespace="default", job_name="example-job"}'
        values: '1+0x20'

    alert_rule_test:
      - eval_time: 20m
        alertname: KubernetesLongRunningJob

  # Node based Alerts
  - interval: 1m
    input_series:
      # Node is running with 100% CPU usage, so it will be alerted.
      - series: 'node_cpu_seconds_total{instance="instance1", mode="idle"}'
        values: '0.01+0x15'
      - series: 'node_cpu_seconds_total{instance="instance2", mode="idle"}'
        values: '0.85+0x10'

    alert_rule_test:
      - eval_time: 15m
        alertname: NodeHighCPU
        exp_alerts:
          - exp_labels:
              severity: warning
              instance: instance1
            exp_annotations:
              summary: "Node High CPU Usage."
              description: "CPU Usage is 100% on node instance1"
              alert_routing_key: perfandscale

  - interval: 1m
    input_series:
      # Node is running under 95% CPU usage, so it will not be alerted.
      - series: 'node_cpu_seconds_total{instance="instance1", mode="idle"}'
        values: '0.75-0.1x10'
      - series: 'node_cpu_seconds_total{instance="instance2", mode="idle"}'
        values: '0.85+0x10'

    alert_rule_test:
      - eval_time: 15m
        alertname: NodeHighCPU

  - interval: 1m
    input_series:
      # Node is running with 98% memory usage, so it will be alerted.
      - series: 'node_memory_MemTotal_bytes{instance="instance1"}'
        values: '100+0x9'
      - series: 'node_memory_MemAvailable_bytes{instance="instance1"}'
        values: '2+0x9'

    alert_rule_test:
      - eval_time: 10m
        alertname: NodeHighMemory
        exp_alerts:
          - exp_labels:
              severity: warning
              instance: instance1
            exp_annotations:
              summary: "Node High Memory Usage."
              description: "Memory Usage is 98% on node instance1"
              alert_routing_key: perfandscale

  - interval: 1m
    input_series:
      # Node is running under 90% memory usage, so it will not be alerted.
      - series: 'node_memory_MemTotal_bytes{instance="instance2"}'
        values: '100x9'
      - series: 'node_memory_MemAvailable_bytes{instance="instance2"}'
        values: '98x9'

    alert_rule_test:
      - eval_time: 10m
        alertname: NodeHighMemory
