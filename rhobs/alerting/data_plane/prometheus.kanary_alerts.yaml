apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: rhtap-kanary-alerting-rules
  labels:
    tenant: rhtap
spec:
  groups:
  - name: kanary_alerts
    interval: 1m
    rules:
      - alert: KanarySignalTriggered
        # For slo alerts only use production metrics (tested_cluster) that are exported from a
        # production cluster (source_clusterj) by the kanary exporter.
        # We have a stage and production exporter, and both are pushing metrics for all konflux clusters to
        # their respective datasource ('rhtap-observatorium-stage' and 'rhtap-observatorium-prod').
        expr: kanary_up{tested_cluster=~".*prod.*", source_cluster=~".*prod.*"} == 0
        for: 1s
        labels:
          severity: critical
          slo: "false"
        annotations:
          alert_team_handle: '<!subteam^S06V06A36F5>'
          team: o11y
          summary: "Kanary signal for {{ $labels.type }} artifacts has been triggered for cluster {{ $labels.tested_cluster }}"
          description: "The e2e load tests for {{ $labels.type }} artifacts failed multiple times in a row for cluster {{ $labels.tested_cluster }}"
          runbook_url: https://gitlab.cee.redhat.com/konflux/docs/sop/-/blob/main/o11y/alert-rule-kanary.md

      - alert: KanaryDBError
        expr: kanary_error{reason="db_error"} == 1
        for: 1s
        labels:
          severity: warning
          slo: "false"
        annotations:
          team: o11y
          alert_routing_key: o11y
          summary: "Kanary signal processing for {{ $labels.type }} artifacts failed due to a database error on cluster {{ $labels.tested_cluster }}"
          description: "Encountered a database error while processing the kanary signal for {{ $labels.type }} artifacts for cluster {{ $labels.tested_cluster }}"

      - alert: KanaryMissingTestResults
        expr: kanary_error{reason="no_test_results"} == 1
        for: 1s
        labels:
          severity: warning
          slo: "false"
        annotations:
          team: o11y
          alert_routing_key: o11y
          summary: "Missing recent e2e results for {{ $labels.type }} artifacts for cluster {{ $labels.tested_cluster }}"
          description: "Could not find any recent e2e load test results for {{ $labels.type }} artifacts for cluster {{ $labels.tested_cluster }}."

      - alert: KanaryExporterDown
        expr: up{job="kanary-exporter-service"} == 0
        for: 5m
        labels:
          severity: warning
          slo: "false"
        annotations:
          team: o11y
          alert_routing_key: o11y
          summary: "Kanary Exporter is down in {{ $labels.source_cluster }}"
          description: "Prometheus is unable to scrape metrics from the Kanary Exporter running in {{ $labels.source_cluster }}."

      - alert: KanaryAbsentExporterMetrics
        # Consideration: the value returned by absent() does not return the source_cluster label.
        # The environment can only be determined by looking at the source alertmanager in the alert's slack message.
        expr: absent(up{job="kanary-exporter-service"}) == 1
        for: 5m
        labels:
          severity: warning
          slo: "false"
        annotations:
          team: o11y
          alert_routing_key: o11y
          summary: "Kanary Exporter metrics are absent"
          description: "Metrics from the Kanary Exporter are absent."
